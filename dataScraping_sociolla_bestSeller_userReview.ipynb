{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e486bde0-5f1d-4b02-a24e-021b839a9d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IDs] Loaded 237 product_ids from best_seller_product_ids.csv\n",
      "[IDs] Using 237 Best Seller product_ids\n",
      "[resume] Detected 8 product_ids already written in dataScraping_sociolla_bestSeller_userReview_140925.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Products:   1%|▌                                                                       | 2/237 [00:03<06:06,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[skip] product_id=3 returned 400/empty across all filter variants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Products:  54%|█████████████████████████████████████▊                                | 128/237 [39:23<03:09,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[skip] product_id=108972 returned 400/empty across all filter variants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Products:  69%|████████████████████████████████████████████████▏                     | 163/237 [41:34<05:09,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[skip] product_id=112195 returned 400/empty across all filter variants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Products:  98%|████████████████████████████████████████████████████████████████████▊ | 233/237 [43:55<00:02,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[skip] product_id=119346 returned 400/empty across all filter variants\n",
      "[skip] product_id=119348 returned 400/empty across all filter variants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Products: 100%|██████████████████████████████████████████████████████████████████████| 237/237 [43:59<00:00, 11.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[done] Saved all reviews to: C:\\Users\\ASUS\\dataScraping_sociolla_bestSeller_userReview_140925.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from curl_cffi import requests as cf\n",
    "from urllib.parse import urlsplit, urlunsplit, urlencode, parse_qsl\n",
    "from tqdm import tqdm\n",
    "import json, time, random, csv, os, re\n",
    "from typing import Any, Dict, Set, List\n",
    "\n",
    "IDS_CSV = \"best_seller_product_ids.csv\"\n",
    "OUT_CSV = \"dataScraping_sociolla_bestSeller_userReview_140925.csv\"  # new file name\n",
    "\n",
    "CAMPAIGN_URL = (\n",
    "    \"https://catalog-api4.sociolla.com/v3/campaigns/best-seller\"\n",
    "    \"?filter=%7B%22type%22:%22best_seller%22%7D\"\n",
    "    \"&fields=_id,is_active,is_display,name,slug,sections,childs,more_info\"\n",
    ")\n",
    "BEST_SELLER_LIST_URL = (\n",
    "    \"https://catalog-api.sociolla.com/v3/products/reviews/best-seller\"\n",
    "    \"?skip=0&limit=10&sort=-created_at\"\n",
    ")\n",
    "\n",
    "REVIEWS_API = \"https://soco-api.sociolla.com/reviews\"\n",
    "\n",
    "BROWSER_HEADERS = {\n",
    "    \"accept\": \"application/json, text/plain, */*\",\n",
    "    \"origin\": \"https://www.sociolla.com\",\n",
    "    \"referer\": \"https://www.sociolla.com/\",\n",
    "    \"soc-platform\": \"sociolla-web-desktop\",\n",
    "}\n",
    "\n",
    "\n",
    "FIELDNAMES = [\n",
    "    \"review_id\", \"product_id\",\n",
    "    \"product.id\", \"product.name\",\n",
    "    \"name\", \"details\",\n",
    "    \"is_recommended\", \"is_repurchase\", \"is_verified_purchase\",\n",
    "    \"lang\", \"duration_of_used\",\n",
    "    \"created_at\", \"updated_at\",\n",
    "    \"images\", \"source\",\n",
    "    \"average_rating\", \"counter_star\",\n",
    "    \"star_long_wear\", \"star_packaging\", \"star_pigmentation\",\n",
    "    \"star_texture\", \"star_value_for_money\",\n",
    "    \"brand.id\", \"brand.name\",\n",
    "    \"product.variant\", \"product.categories\",\n",
    "    \"counter_review_rating\", \"counter_review_star\", \"counter_review_user\",\n",
    "    \"is_active_in_offline_store\", \"is_active_in_review\", \"is_active_in_sociolla\",\n",
    "    \"is_buy_one_get_one_free\", \"is_in_stock\", \"is_in_stock_sociolla\",\n",
    "    \"is_reviewed\", \"is_reviewed_combination\", \"is_sale\", \"is_status\",\n",
    "    \"max_price\", \"max_price_after_discount\", \"min_price\", \"min_price_after_discount\",\n",
    "    \"star_effectiveness\", \"star_scent\", \n",
    "    \"total_likes\",\n",
    "    \"url_sociolla\",\n",
    "]\n",
    "\n",
    "\n",
    "def backoff_sleep(attempt: int):\n",
    "    time.sleep(1.0 * (2 ** attempt) + random.random())\n",
    "\n",
    "def get_json(sess: cf.Session, url: str, headers: Dict[str, str], tries: int = 5):\n",
    "    for attempt in range(tries):\n",
    "        try:\n",
    "            r = sess.get(url, headers=headers, timeout=30)\n",
    "            r.raise_for_status()\n",
    "            return r.json()\n",
    "        except Exception:\n",
    "            if attempt == tries - 1:\n",
    "                raise\n",
    "            backoff_sleep(attempt)\n",
    "\n",
    "def deep_collect_product_ids(obj: Any, ids: Set[int]):\n",
    "    def to_pid(v):\n",
    "        if isinstance(v, int) and v > 0: return v\n",
    "        if isinstance(v, str) and v.isdigit(): return int(v)\n",
    "        return None\n",
    "    if isinstance(obj, dict):\n",
    "        for k in (\"product_id\", \"productId\", \"id\"):\n",
    "            if k in obj:\n",
    "                pid = to_pid(obj[k])\n",
    "                if pid: ids.add(pid)\n",
    "        prod = obj.get(\"product\")\n",
    "        if isinstance(prod, dict):\n",
    "            for k in (\"id\", \"product_id\", \"productId\"):\n",
    "                pid = to_pid(prod.get(k))\n",
    "                if pid: ids.add(pid)\n",
    "        for k in (\"url\", \"link\", \"href\", \"path\", \"slug\"):\n",
    "            v = obj.get(k)\n",
    "            if isinstance(v, str):\n",
    "                m = re.search(r\"/p/(\\d+)(?:[-/]|$)\", v)\n",
    "                if m: ids.add(int(m.group(1)))\n",
    "        for v in obj.values():\n",
    "            deep_collect_product_ids(v, ids)\n",
    "    elif isinstance(obj, list):\n",
    "        for it in obj:\n",
    "            deep_collect_product_ids(it, ids)\n",
    "\n",
    "def paginate_best_seller_list(sess: cf.Session, base_url: str, headers: Dict[str, str]) -> Set[int]:\n",
    "    parts = urlsplit(base_url)\n",
    "    base = parts._replace(query=\"\")\n",
    "    params = dict(parse_qsl(parts.query, keep_blank_values=True))\n",
    "    skip = int(params.get(\"skip\", \"0\") or \"0\")\n",
    "    limit = int(params.get(\"limit\", \"50\") or \"50\")\n",
    "    params.setdefault(\"limit\", str(limit))\n",
    "    params.setdefault(\"sort\", \"-created_at\")\n",
    "\n",
    "    found: Set[int] = set()\n",
    "    page = 0\n",
    "    while True:\n",
    "        params[\"skip\"] = str(skip)\n",
    "        url = urlunsplit(base._replace(query=urlencode(params)))\n",
    "        data = get_json(sess, url, headers)\n",
    "        before = len(found)\n",
    "        deep_collect_product_ids(data, found)\n",
    "\n",
    "        items_len = 0\n",
    "        if isinstance(data, dict):\n",
    "            for k in (\"items\", \"products\", \"data\", \"result\", \"results\", \"records\"):\n",
    "                v = data.get(k)\n",
    "                if isinstance(v, list):\n",
    "                    items_len = len(v); break\n",
    "        elif isinstance(data, list):\n",
    "            items_len = len(data)\n",
    "\n",
    "        if items_len < limit: break\n",
    "        if len(found) == before and page > 0: break\n",
    "\n",
    "        skip += limit; page += 1\n",
    "        time.sleep(0.25 + random.random() * 0.25)\n",
    "\n",
    "    return found\n",
    "\n",
    "def load_or_harvest_best_seller_ids(sess: cf.Session) -> List[int]:\n",
    "    if os.path.exists(IDS_CSV):\n",
    "        with open(IDS_CSV, newline=\"\", encoding=\"utf-8\") as f:\n",
    "            next(f)  # skip header\n",
    "            ids = [int(row.strip()) for row in f if row.strip().isdigit()]\n",
    "        print(f\"[IDs] Loaded {len(ids)} product_ids from {IDS_CSV}\")\n",
    "        return sorted(set(ids))\n",
    "\n",
    "    all_ids: Set[int] = set()\n",
    "    try:\n",
    "        campaign_json = get_json(sess, CAMPAIGN_URL, BROWSER_HEADERS)\n",
    "        deep_collect_product_ids(campaign_json, all_ids)\n",
    "        print(f\"[campaigns] collected {len(all_ids)} ids so far\")\n",
    "    except Exception as e:\n",
    "        print(\"[campaigns] skipped due to error:\", e)\n",
    "\n",
    "    try:\n",
    "        ids_from_list = paginate_best_seller_list(sess, BEST_SELLER_LIST_URL, BROWSER_HEADERS)\n",
    "        all_ids |= ids_from_list\n",
    "        print(f\"[products/reviews/best-seller] collected {len(ids_from_list)} ids; total {len(all_ids)}\")\n",
    "    except Exception as e:\n",
    "        print(\"[products/reviews/best-seller] skipped due to error:\", e)\n",
    "\n",
    "    with open(IDS_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.writer(f); w.writerow([\"product_id\"])\n",
    "        for pid in sorted(all_ids): w.writerow([pid])\n",
    "    print(f\"[IDs] Saved to {os.path.abspath(IDS_CSV)} (count={len(all_ids)})\")\n",
    "    return sorted(all_ids)\n",
    "\n",
    "\n",
    "def _request_with_handling(sess, url, headers, params, max_retries=4):\n",
    "    \"\"\"\n",
    "    Make a GET with retries for transient errors.\n",
    "    Returns (response or None, fatal_bad_request: bool).\n",
    "    fatal_bad_request=True means 4xx bad filter (400/422) -> try next variant.\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            r = sess.get(url, headers=headers, params=params, timeout=30)\n",
    "            if r.status_code in (400, 422):\n",
    "                return None, True\n",
    "            if r.status_code in (429, 500, 502, 503, 504):\n",
    "                backoff_sleep(attempt)\n",
    "                continue\n",
    "            r.raise_for_status()\n",
    "            return r, False\n",
    "        except Exception:\n",
    "            if attempt == max_retries - 1:\n",
    "                return None, True\n",
    "            backoff_sleep(attempt)\n",
    "    return None, True\n",
    "\n",
    "def fetch_reviews_for_product(sess, product_id: int, limit=50, max_reviews=100000):\n",
    "    \"\"\"\n",
    "    Try multiple filter variants to avoid 400/422 for certain products.\n",
    "    Returns a list of reviews; never raises on 400/422 — it skips politely.\n",
    "    \"\"\"\n",
    "    variants = [\n",
    "        {\"is_published\": True, \"elastic_search\": True,  \"product_id\": product_id},\n",
    "        {\"is_published\": True,                          \"product_id\": product_id},\n",
    "        {\"is_published\": True, \"elastic_search\": True,  \"product_id\": str(product_id)},\n",
    "        {\"is_published\": True,                          \"product_id\": str(product_id)},\n",
    "        {\"is_published\": True, \"product_id\": product_id, \"is_highlight\": True},  # subset fallback\n",
    "    ]\n",
    "\n",
    "    for flt in variants:\n",
    "        out = []\n",
    "        hit_any_page = False\n",
    "\n",
    "        for skip in range(0, max_reviews, limit):\n",
    "            params = {\n",
    "                \"filter\": json.dumps(flt, ensure_ascii=False),\n",
    "                \"skip\": skip,\n",
    "                \"limit\": limit,\n",
    "                \"sort\": \"most_relevant\",  \n",
    "            }\n",
    "\n",
    "            resp, fatal_bad = _request_with_handling(sess, REVIEWS_API, BROWSER_HEADERS, params)\n",
    "            if fatal_bad:\n",
    "                break\n",
    "\n",
    "            hit_any_page = True\n",
    "            data = resp.json()\n",
    "            items = data.get(\"data\") or data.get(\"items\") or []\n",
    "            if not items:\n",
    "                break\n",
    "\n",
    "            out.extend(items)\n",
    "            if len(items) < limit:\n",
    "                break\n",
    "\n",
    "            # polite pacing\n",
    "            time.sleep(0.35 + random.random() * 0.25)\n",
    "\n",
    "        if out:\n",
    "            return out \n",
    "        if hit_any_page:\n",
    "            break\n",
    "\n",
    "    print(f\"[skip] product_id={product_id} returned 400/empty across all filter variants\")\n",
    "    return []\n",
    "\n",
    "\n",
    "def _list_to_csv(items, key_candidates=None):\n",
    "    if not items: return \"\"\n",
    "    out = []\n",
    "    for it in items:\n",
    "        if isinstance(it, str):\n",
    "            out.append(it)\n",
    "        elif isinstance(it, dict):\n",
    "            picked = None\n",
    "            if key_candidates:\n",
    "                for k in key_candidates:\n",
    "                    v = it.get(k)\n",
    "                    if v not in (None, \"\"):\n",
    "                        picked = str(v); break\n",
    "            out.append(picked if picked is not None else json.dumps(it, ensure_ascii=False))\n",
    "        else:\n",
    "            out.append(str(it))\n",
    "    return \",\".join(out)\n",
    "\n",
    "def _get_nested(d: dict, path: List[str], default=None):\n",
    "    cur = d\n",
    "    for p in path:\n",
    "        if not isinstance(cur, dict): return default\n",
    "        cur = cur.get(p)\n",
    "        if cur is None: return default\n",
    "    return cur\n",
    "\n",
    "def to_row(rv):\n",
    "    product_obj = rv.get(\"product\") or {}\n",
    "    brand = product_obj.get(\"brand\") or {}\n",
    "    stars = rv.get(\"stars\") or rv.get(\"star\") or {}\n",
    "    def star_of(key_flat, key_nested, product_key=None):\n",
    "        if key_flat in rv:  # review-level flat\n",
    "            return rv.get(key_flat)\n",
    "        if key_nested and isinstance(stars, dict) and key_nested in stars:  \n",
    "            return stars.get(key_nested)\n",
    "        if product_key and product_key in product_obj:  \n",
    "            return product_obj.get(product_key)\n",
    "        return None\n",
    "\n",
    "    categories_csv = _list_to_csv(product_obj.get(\"categories\", []), key_candidates=[\"name\", \"slug\", \"title\"])\n",
    "\n",
    "    return {\n",
    "        \"review_id\": rv.get(\"_id\"),\n",
    "        \"product_id\": rv.get(\"product_id\"),\n",
    "        \"product.id\": product_obj.get(\"id\") or rv.get(\"product_id\"),\n",
    "        \"product.name\": product_obj.get(\"name\"),\n",
    "        \"name\": rv.get(\"name\") or _get_nested(rv, [\"user\",\"name\"]),\n",
    "        \"details\": rv.get(\"details\"),\n",
    "        \"is_recommended\": rv.get(\"is_recommended\"),\n",
    "        \"is_repurchase\": rv.get(\"is_repurchase\"),\n",
    "        \"is_verified_purchase\": rv.get(\"is_verified_purchase\"),\n",
    "        \"lang\": rv.get(\"lang\"),\n",
    "        \"duration_of_used\": rv.get(\"duration_of_used\"),\n",
    "        \"created_at\": rv.get(\"created_at\"),\n",
    "        \"updated_at\": rv.get(\"updated_at\") or rv.get(\"edited_at\"),\n",
    "        \"images\": _list_to_csv(rv.get(\"images\", []), key_candidates=[\"name\", \"url\", \"src\"]),\n",
    "        \"source\": rv.get(\"source\"),\n",
    "        \"average_rating\": rv.get(\"average_rating\") or product_obj.get(\"average_rating\"),\n",
    "        \"counter_star\":   rv.get(\"counter_star\")   or product_obj.get(\"counter_star\"),\n",
    "        \"star_long_wear\":      star_of(\"star_long_wear\", \"long_wear\", \"star_long_wear\"),\n",
    "        \"star_packaging\":      star_of(\"star_packaging\", \"packaging\", \"star_packaging\"),\n",
    "        \"star_pigmentation\":   star_of(\"star_pigmentation\", \"pigmentation\", \"star_pigmentation\"),\n",
    "        \"star_texture\":        star_of(\"star_texture\", \"texture\", \"star_texture\"),\n",
    "        \"star_value_for_money\":star_of(\"star_value_for_money\", \"value_for_money\", \"star_value_for_money\"),\n",
    "        \"brand.id\": brand.get(\"id\") or brand.get(\"_id\") or brand.get(\"slug\"),\n",
    "        \"brand.name\": brand.get(\"name\") or brand.get(\"title\"),\n",
    "        \"product.variant\": product_obj.get(\"variant\"),\n",
    "        \"product.categories\": categories_csv,\n",
    "        \"counter_review_rating\": product_obj.get(\"counter_review_rating\") or rv.get(\"counter_review_rating\"),\n",
    "        \"counter_review_star\":   product_obj.get(\"counter_review_star\")   or rv.get(\"counter_review_star\"),\n",
    "        \"counter_review_user\":   product_obj.get(\"counter_review_user\")   or rv.get(\"counter_review_user\"),\n",
    "        \"is_active_in_offline_store\": product_obj.get(\"is_active_in_offline_store\"),\n",
    "        \"is_active_in_review\":        product_obj.get(\"is_active_in_review\"),\n",
    "        \"is_active_in_sociolla\":      product_obj.get(\"is_active_in_sociolla\"),\n",
    "        \"is_buy_one_get_one_free\":    product_obj.get(\"is_buy_one_get_one_free\"),\n",
    "        \"is_in_stock\":                product_obj.get(\"is_in_stock\"),\n",
    "        \"is_in_stock_sociolla\":       product_obj.get(\"is_in_stock_sociolla\"),\n",
    "        \"is_reviewed\":                product_obj.get(\"is_reviewed\"),\n",
    "        \"is_reviewed_combination\":    product_obj.get(\"is_reviewed_combination\"),\n",
    "        \"is_sale\":                    product_obj.get(\"is_sale\"),\n",
    "        \"is_status\":                  product_obj.get(\"is_status\"),\n",
    "        \"max_price\":                  product_obj.get(\"max_price\"),\n",
    "        \"max_price_after_discount\":   product_obj.get(\"max_price_after_discount\"),\n",
    "        \"min_price\":                  product_obj.get(\"min_price\"),\n",
    "        \"min_price_after_discount\":   product_obj.get(\"min_price_after_discount\"),\n",
    "        \"star_effectiveness\":         product_obj.get(\"star_effectiveness\"),\n",
    "        \"star_scent\":                 product_obj.get(\"star_scent\"),\n",
    "        \"total_likes\":                product_obj.get(\"total_likes\"),\n",
    "        \"url_sociolla\":               product_obj.get(\"url_sociolla\") or product_obj.get(\"url\") or product_obj.get(\"link\"),\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sess = cf.Session(impersonate=\"chrome\")\n",
    "\n",
    "    product_ids = load_or_harvest_best_seller_ids(sess)\n",
    "    print(f\"[IDs] Using {len(product_ids)} Best Seller product_ids\")\n",
    "\n",
    "    already = set()\n",
    "    if os.path.exists(OUT_CSV):\n",
    "        with open(OUT_CSV, newline=\"\", encoding=\"utf-8\") as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for row in reader:\n",
    "                if row.get(\"product_id\") and str(row[\"product_id\"]).isdigit():\n",
    "                    already.add(int(row[\"product_id\"]))\n",
    "        print(f\"[resume] Detected {len(already)} product_ids already written in {OUT_CSV}\")\n",
    "\n",
    "    write_header = not os.path.exists(OUT_CSV)\n",
    "    with open(OUT_CSV, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=FIELDNAMES)\n",
    "        if write_header:\n",
    "            writer.writeheader()\n",
    "\n",
    "        for pid in tqdm(product_ids, desc=\"Products\"):\n",
    "            if pid in already:\n",
    "                continue\n",
    "\n",
    "            reviews = fetch_reviews_for_product(sess, pid, limit=50)\n",
    "            if not reviews:\n",
    "                continue\n",
    "\n",
    "            for rv in reviews:\n",
    "                try:\n",
    "                    writer.writerow(to_row(rv))\n",
    "                except Exception as e:\n",
    "                    print(\"Skip row due to error:\", e)\n",
    "\n",
    "            time.sleep(0.3 + random.random() * 0.3)\n",
    "\n",
    "    print(f\"[done] Saved all reviews to: {os.path.abspath(OUT_CSV)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254bd83f-fc1b-4649-bf09-26417388a4e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
